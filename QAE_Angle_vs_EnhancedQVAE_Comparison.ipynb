{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1585aa56",
   "metadata": {},
   "source": [
    "# Quantum Autoencoder: Angle vs Enhanced qVAE Comparison\n",
    "\n",
    "**Simplified comparison between two key embedding strategies for fraud detection:**\n",
    "\n",
    "1. **`angle`**: Standard AngleEmbedding baseline (4 qubits)\n",
    "2. **`enhanced_qvae`**: Advanced research-based qVAE (13 qubits total)\n",
    "\n",
    "**Based on**: \"The role of data embedding in quantum autoencoders for improved anomaly detection\" (IEEE Access 2024)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Differences:\n",
    "\n",
    "### Standard Angle Embedding:\n",
    "- Simple RY rotations for feature encoding\n",
    "- 4 qubits total\n",
    "- Fast training and execution\n",
    "- Standard baseline approach\n",
    "\n",
    "### Enhanced qVAE:\n",
    "- Data re-uploading at each layer\n",
    "- Parallel embedding (2x replication = 8 data qubits)\n",
    "- Alternate RY/RX rotations\n",
    "- SWAP test measurement for quantum fidelity\n",
    "- 13 qubits total (8 data + 2 reference + 2 trash + 1 control)\n",
    "\n",
    "**Goal**: Determine if the advanced qVAE techniques provide meaningful improvement over the standard approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf356b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PennyLane version: 0.41.1\n"
     ]
    }
   ],
   "source": [
    "# Core libraries for data processing and machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, roc_auc_score)\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# Quantum machine learning framework\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as pnp\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3636c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 946 samples, 30 features\n",
      "Fraud rate: 0.5000 (473 fraud cases)\n",
      "\n",
      "Training set: (756, 4)\n",
      "Test set: (190, 4)\n",
      "PCA explained variance ratio: [0.38421646 0.10954544 0.06067923 0.05752846]\n",
      "Total variance explained: 0.6120\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Data Loading and Preprocessing Pipeline\n",
    "# ==========================================\n",
    "\n",
    "# Load preprocessed credit card fraud dataset\n",
    "df = pd.read_csv(\"preprocessed-creditcard.csv\")\n",
    "X = df.drop(\"Class\", axis=1).values  # Feature matrix\n",
    "y = df[\"Class\"].values                # Target labels (0: normal, 1: fraud)\n",
    "\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Fraud rate: {np.mean(y):.4f} ({np.sum(y)} fraud cases)\")\n",
    "\n",
    "# Stratified train-test split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature standardization using Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# Dimensionality reduction using PCA to match quantum register size\n",
    "pca = PCA(n_components=4, random_state=42)\n",
    "X_train_4d = pca.fit_transform(X_train)\n",
    "X_test_4d  = pca.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train_4d.shape}\")\n",
    "print(f\"Test set: {X_test_4d.shape}\")\n",
    "print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {np.sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d44d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTUM AUTOENCODER - ANGLE vs ENHANCED qVAE COMPARISON\n",
      "================================================================================\n",
      "Enhanced qVAE Configuration:\n",
      "  - Data Re-uploading: True\n",
      "  - Parallel Embedding: 2x (8 data qubits)\n",
      "  - Alternate RY/RX: True\n",
      "  - SWAP Test: True\n",
      "  - Total qubits: 13 (8 data + 2 ref + 2 trash + 1 control)\n",
      "\n",
      "Training Configuration: {'epochs_angle': 100, 'epochs_qvae': 100, 'batch_size_angle': 16, 'batch_size_qvae': 16, 'learning_rate': 0.001}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Configuration for Two-Strategy Comparison\n",
    "# ==========================================\n",
    "\n",
    "# ENHANCED qVAE FEATURES\n",
    "USE_DATA_REUPLOADING = True     # Embed data at each variational layer\n",
    "USE_PARALLEL_EMBEDDING = 2      # Replicate data across multiple qubits (2x = 8 data qubits)\n",
    "USE_ALTERNATE_EMBEDDING = True  # Alternate between RY and RX rotations\n",
    "USE_SWAP_TEST = True           # Use quantum SWAP test for accurate fidelity measurement\n",
    "\n",
    "# QUANTUM ARCHITECTURE PARAMETERS\n",
    "N_REFERENCE_QUBITS = 2  # Reference qubits for SWAP test\n",
    "N_TRASH_QUBITS = 2     # Trash qubits for SWAP test\n",
    "\n",
    "# TRAINING CONFIGURATION\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs_angle': 100,        # Standard angle embedding\n",
    "    'epochs_qvae': 100,         # Enhanced qVAE (needs more epochs)\n",
    "    'batch_size_angle': 16,    # Standard strategy\n",
    "    'batch_size_qvae': 16,      # Enhanced qVAE (memory intensive)\n",
    "    'learning_rate': 0.001      # Adam optimizer stepsize\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUANTUM AUTOENCODER - ANGLE vs ENHANCED qVAE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Enhanced qVAE Configuration:\")\n",
    "print(f\"  - Data Re-uploading: {USE_DATA_REUPLOADING}\")\n",
    "print(f\"  - Parallel Embedding: {USE_PARALLEL_EMBEDDING}x (8 data qubits)\")\n",
    "print(f\"  - Alternate RY/RX: {USE_ALTERNATE_EMBEDDING}\")\n",
    "print(f\"  - SWAP Test: {USE_SWAP_TEST}\")\n",
    "print(f\"  - Total qubits: 13 (8 data + 2 ref + 2 trash + 1 control)\")\n",
    "print(f\"\\nTraining Configuration: {TRAINING_CONFIG}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dfd0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum circuit functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Quantum Circuit Architectures\n",
    "# ==========================================\n",
    "\n",
    "# Common layer functions\n",
    "L = 4  # Number of variational layers\n",
    "\n",
    "def qae_layer(theta):\n",
    "    \"\"\"\n",
    "    Single variational layer with parameterized rotations and entanglement.\n",
    "    \n",
    "    Args:\n",
    "        theta: Parameter tensor of shape (n_qubits, 3) for rotation angles\n",
    "    \"\"\"\n",
    "    n_qubits = theta.shape[0]\n",
    "    # Apply parameterized rotations to each qubit\n",
    "    for w in range(n_qubits):\n",
    "        qml.RX(theta[w, 0], wires=w)\n",
    "        qml.RY(theta[w, 1], wires=w) \n",
    "        qml.RZ(theta[w, 2], wires=w)\n",
    "    \n",
    "    # Circular entangling layer using CNOT gates\n",
    "    for w in range(n_qubits):\n",
    "        qml.CNOT(wires=[w, (w + 1) % n_qubits])\n",
    "\n",
    "def enhanced_qvae_layer(inputs, weights, layer_idx, n_layers, n_qubits, reupload=True, alternate_embedding=False):\n",
    "    \"\"\"\n",
    "    Enhanced qVAE layer with data re-uploading and advanced embedding.\n",
    "    \n",
    "    Based on the implementation from 'The role of data embedding in quantum autoencoders \n",
    "    for improved anomaly detection' paper.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input data features\n",
    "        weights: Trainable parameters for this layer\n",
    "        layer_idx: Current layer index\n",
    "        n_layers: Total number of layers\n",
    "        n_qubits: Number of data qubits\n",
    "        reupload: Whether to use data re-uploading\n",
    "        alternate_embedding: Whether to alternate between RY and RX\n",
    "    \"\"\"\n",
    "    # Data embedding (with re-uploading if enabled)\n",
    "    if not reupload or layer_idx == 0:  # Always embed on first layer\n",
    "        for i, feature in enumerate(inputs):\n",
    "            # Parallel embedding: replicate data across multiple qubits\n",
    "            for p in range(USE_PARALLEL_EMBEDDING):\n",
    "                qubit_idx = i * USE_PARALLEL_EMBEDDING + p\n",
    "                if qubit_idx < n_qubits:\n",
    "                    if alternate_embedding and (i + p) % 2 == 1:\n",
    "                        qml.RX(feature, wires=qubit_idx)\n",
    "                    else:\n",
    "                        qml.RY(feature, wires=qubit_idx)\n",
    "    \n",
    "    # Parameterized rotations for each qubit\n",
    "    for w in range(n_qubits):\n",
    "        qml.RY(weights[w, 0], wires=w)\n",
    "        qml.RZ(weights[w, 1], wires=w)\n",
    "    \n",
    "    # Entangling gates with periodic boundary\n",
    "    if n_qubits > 1:\n",
    "        for w in range(n_qubits):\n",
    "            control = w\n",
    "            target = (w + 1) % n_qubits\n",
    "            qml.CNOT(wires=[control, target])\n",
    "    \n",
    "    # Data re-uploading for intermediate layers\n",
    "    if reupload and layer_idx < n_layers - 1:\n",
    "        for i, feature in enumerate(inputs):\n",
    "            for p in range(USE_PARALLEL_EMBEDDING):\n",
    "                qubit_idx = i * USE_PARALLEL_EMBEDDING + p\n",
    "                if qubit_idx < n_qubits:\n",
    "                    if alternate_embedding and (i + p) % 2 == 1:\n",
    "                        qml.RX(feature, wires=qubit_idx)\n",
    "                    else:\n",
    "                        qml.RY(feature, wires=qubit_idx)\n",
    "\n",
    "def swap_test_measurement(n_data_qubits, n_ref_qubits, total_qubits, n_trash):\n",
    "    \"\"\"\n",
    "    Implement SWAP test for quantum fidelity measurement.\n",
    "    \n",
    "    The SWAP test measures the overlap between the output state and reference state,\n",
    "    providing a more accurate fidelity estimate than simple Pauli measurements.\n",
    "    \n",
    "    Args:\n",
    "        n_data_qubits: Number of data qubits\n",
    "        n_ref_qubits: Number of reference qubits\n",
    "        total_qubits: Total number of qubits in the circuit\n",
    "        n_trash: Number of trash qubits\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value related to quantum fidelity\n",
    "    \"\"\"\n",
    "    control_qubit = total_qubits - 1  # Last qubit as control\n",
    "    \n",
    "    # Apply Hadamard to control qubit\n",
    "    qml.Hadamard(wires=control_qubit)\n",
    "    \n",
    "    # Controlled SWAP operations between data and reference qubits\n",
    "    data_start = n_data_qubits - n_ref_qubits\n",
    "    ref_start = n_data_qubits\n",
    "    \n",
    "    for i in range(n_ref_qubits):\n",
    "        data_qubit = data_start + i\n",
    "        ref_qubit = ref_start + i\n",
    "        if data_qubit < n_data_qubits and ref_qubit < ref_start + n_trash:\n",
    "            qml.CSWAP(wires=[control_qubit, data_qubit, ref_qubit])\n",
    "    \n",
    "    # Final Hadamard on control qubit\n",
    "    qml.Hadamard(wires=control_qubit)\n",
    "    \n",
    "    # Measure control qubit\n",
    "    return qml.expval(qml.PauliZ(control_qubit))\n",
    "\n",
    "print(\"Quantum circuit functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52f1fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategies implemented successfully!\n",
      "  - angle: Standard AngleEmbedding (4 qubits)\n",
      "  - enhanced_qvae: Advanced qVAE (13 qubits total)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Embedding Strategy Implementations\n",
    "# ==========================================\n",
    "\n",
    "def angle_embedding_circuit(x, weights, n_qubits):\n",
    "    \"\"\"\n",
    "    Standard AngleEmbedding strategy - baseline approach.\n",
    "    \n",
    "    Simple and reliable RY rotations for feature encoding.\n",
    "    Each feature is encoded as a rotation angle on its corresponding qubit.\n",
    "    \"\"\"\n",
    "    qml.AngleEmbedding(features=x, wires=range(min(len(x), n_qubits)), rotation=\"Y\")\n",
    "    \n",
    "    # Apply variational layers\n",
    "    for l in range(L):\n",
    "        qae_layer(weights[l])\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(n_qubits - 1))\n",
    "\n",
    "def enhanced_qvae_circuit(x, weights, n_qubits, total_qubits):\n",
    "    \"\"\"\n",
    "    Enhanced qVAE circuit implementing the advanced techniques from the research paper:\n",
    "    - Data re-uploading: Embeds data at each variational layer\n",
    "    - Parallel embedding: Replicates data across multiple qubits\n",
    "    - Alternate embedding: Alternates between RY and RX rotations\n",
    "    - SWAP test measurement: Quantum fidelity measurement with reference qubits\n",
    "    \"\"\"\n",
    "    # Apply enhanced qVAE layers with data re-uploading\n",
    "    for l in range(L):\n",
    "        enhanced_qvae_layer(\n",
    "            inputs=x,\n",
    "            weights=weights[l],\n",
    "            layer_idx=l,\n",
    "            n_layers=L,\n",
    "            n_qubits=n_qubits,\n",
    "            reupload=USE_DATA_REUPLOADING,\n",
    "            alternate_embedding=USE_ALTERNATE_EMBEDDING\n",
    "        )\n",
    "    \n",
    "    # Choose measurement strategy\n",
    "    if USE_SWAP_TEST and total_qubits > n_qubits:\n",
    "        return swap_test_measurement(n_qubits, N_REFERENCE_QUBITS, total_qubits, N_TRASH_QUBITS)\n",
    "    else:\n",
    "        return qml.expval(qml.PauliZ(n_qubits - 1))\n",
    "\n",
    "print(\"Embedding strategies implemented successfully!\")\n",
    "print(f\"  - angle: Standard AngleEmbedding (4 qubits)\")\n",
    "print(f\"  - enhanced_qvae: Advanced qVAE (13 qubits total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3423b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Training Functions\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# 전역 함수로 batch_cost 함수 구현\n",
    "def compute_batch_cost(samples, circuit, weights, use_swap_test=False):\n",
    "    \"\"\"\n",
    "    배치 비용 계산을 위한 전역 함수\n",
    "\n",
    "    Args:\n",
    "        samples: 배치 데이터 샘플\n",
    "        circuit: 양자 회로\n",
    "        weights: 가중치 파라미터\n",
    "        use_swap_test: SWAP 테스트 사용 여부\n",
    "\n",
    "    Returns:\n",
    "        linear_loss: 선형 손실값 (Linear loss)\n",
    "        squared_loss: 제곱 손실값 (Squared loss)\n",
    "    \"\"\"\n",
    "    linear_errors = []\n",
    "    squared_errors = []\n",
    "\n",
    "    for sample in samples:\n",
    "        features = pnp.array(sample, requires_grad=False)\n",
    "        expval = circuit(features, weights)\n",
    "\n",
    "        # 충실도(fidelity) 계산\n",
    "        fidelity = (expval + 1.0) / 2.0\n",
    "\n",
    "        # 선형 손실 계산 (Linear loss)\n",
    "        linear_error = 1.0 - fidelity\n",
    "        linear_errors.append(linear_error)\n",
    "\n",
    "        # 제곱 손실 계산 (Squared loss)\n",
    "        squared_error = (1.0 - fidelity) ** 2\n",
    "        squared_errors.append(squared_error)\n",
    "\n",
    "    linear_loss = pnp.mean(pnp.stack(linear_errors))\n",
    "    squared_loss = pnp.mean(pnp.stack(squared_errors))\n",
    "\n",
    "    # SWAP 테스트를 사용하는 경우 선형 손실을 기본값으로,\n",
    "    # 그렇지 않은 경우 제곱 손실을 기본값으로 반환\n",
    "    return linear_loss, squared_loss\n",
    "\n",
    "\n",
    "def train_angle_strategy():\n",
    "    \"\"\"\n",
    "    Train the standard angle embedding strategy.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING: ANGLE EMBEDDING STRATEGY\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create quantum device and circuit\n",
    "    n_qubits = 4\n",
    "    dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def angle_circuit(x, weights):\n",
    "        return angle_embedding_circuit(x, weights, n_qubits)\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = pnp.random.uniform(-pnp.pi, pnp.pi, (L, n_qubits, 3), requires_grad=True)\n",
    "\n",
    "    # Training configuration\n",
    "    epochs = TRAINING_CONFIG[\"epochs_angle\"]\n",
    "    batch_size = TRAINING_CONFIG[\"batch_size_angle\"]\n",
    "    optimizer = qml.AdamOptimizer(stepsize=TRAINING_CONFIG[\"learning_rate\"])\n",
    "\n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"  - Qubits: {n_qubits}\")\n",
    "    print(f\"  - Parameters: {np.prod(weights.shape)}\")\n",
    "    print(f\"  - Epochs: {epochs}, Batch size: {batch_size}\")\n",
    "\n",
    "    # Training loop\n",
    "    training_losses = []\n",
    "    linear_losses = []\n",
    "    squared_losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_linear_losses = []\n",
    "        epoch_squared_losses = []\n",
    "\n",
    "        for batch_start in range(0, len(X_train_4d), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_train_4d))\n",
    "            X_batch = X_train_4d[batch_start:batch_end]\n",
    "\n",
    "            # 배치 비용 함수 래퍼\n",
    "            def batch_cost_wrapper(w):\n",
    "                linear_loss, squared_loss = compute_batch_cost(\n",
    "                    X_batch, angle_circuit, w, False\n",
    "                )\n",
    "                # 제곱 손실을 기본 최적화 목표로 사용\n",
    "                return squared_loss\n",
    "\n",
    "            # Optimize weights\n",
    "            weights = optimizer.step(batch_cost_wrapper, weights)\n",
    "\n",
    "            # Record loss\n",
    "            linear_loss, squared_loss = compute_batch_cost(\n",
    "                X_batch, angle_circuit, weights, False\n",
    "            )\n",
    "            epoch_linear_losses.append(float(linear_loss))\n",
    "            epoch_squared_losses.append(float(squared_loss))\n",
    "\n",
    "        # Epoch summary\n",
    "        avg_linear_loss = np.mean(epoch_linear_losses)\n",
    "        avg_squared_loss = np.mean(epoch_squared_losses)\n",
    "        linear_losses.append(avg_linear_loss)\n",
    "        squared_losses.append(avg_squared_loss)\n",
    "\n",
    "        # 모델 최적화에는 제곱 손실을 주로 사용\n",
    "        training_losses.append(avg_squared_loss)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            print(\n",
    "                f\"  Epoch {epoch+1:2d}/{epochs} - Linear Loss: {avg_linear_loss:.6f}, Squared Loss: {avg_squared_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Training completed in {training_time:.1f}s - Final loss: {training_losses[-1]:.6f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"strategy\": \"angle\",\n",
    "        \"weights\": weights,\n",
    "        \"losses\": training_losses,\n",
    "        \"linear_losses\": linear_losses,\n",
    "        \"squared_losses\": squared_losses,\n",
    "        \"circuit\": angle_circuit,\n",
    "        \"n_qubits\": n_qubits,\n",
    "        \"total_qubits\": n_qubits,\n",
    "        \"training_time\": training_time,\n",
    "        \"final_loss\": training_losses[-1],\n",
    "    }\n",
    "\n",
    "\n",
    "def train_enhanced_qvae_strategy():\n",
    "    \"\"\"\n",
    "    Train the enhanced qVAE strategy.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING: ENHANCED qVAE STRATEGY\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create quantum device and circuit\n",
    "    n_qubits = 4 * USE_PARALLEL_EMBEDDING  # 8 data qubits\n",
    "    total_qubits = n_qubits + N_REFERENCE_QUBITS + N_TRASH_QUBITS + 1  # 13 total\n",
    "    dev = qml.device(\"lightning.qubit\", wires=total_qubits)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def qvae_circuit(x, weights):\n",
    "        return enhanced_qvae_circuit(x, weights, n_qubits, total_qubits)\n",
    "\n",
    "    # Initialize weights (enhanced qVAE uses 2 parameters per qubit per layer)\n",
    "    weights = pnp.random.uniform(-pnp.pi, pnp.pi, (L, n_qubits, 2), requires_grad=True)\n",
    "\n",
    "    # Training configuration\n",
    "    epochs = TRAINING_CONFIG[\"epochs_qvae\"]\n",
    "    batch_size = TRAINING_CONFIG[\"batch_size_qvae\"]\n",
    "    optimizer = qml.AdamOptimizer(stepsize=TRAINING_CONFIG[\"learning_rate\"])\n",
    "\n",
    "    print(f\"Configuration:\")\n",
    "    print(\n",
    "        f\"  - Data Qubits: {n_qubits} (4 features × {USE_PARALLEL_EMBEDDING} parallel)\"\n",
    "    )\n",
    "    print(f\"  - Total Qubits: {total_qubits}\")\n",
    "    print(f\"  - Parameters: {np.prod(weights.shape)}\")\n",
    "    print(f\"  - Epochs: {epochs}, Batch size: {batch_size}\")\n",
    "    print(\n",
    "        f\"  - Features: Re-upload={USE_DATA_REUPLOADING}, Alternate={USE_ALTERNATE_EMBEDDING}, SWAP={USE_SWAP_TEST}\"\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    training_losses = []\n",
    "    linear_losses = []\n",
    "    squared_losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_linear_losses = []\n",
    "        epoch_squared_losses = []\n",
    "\n",
    "        for batch_start in range(0, len(X_train_4d), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_train_4d))\n",
    "            X_batch = X_train_4d[batch_start:batch_end]\n",
    "\n",
    "            # 배치 비용 함수 래퍼\n",
    "            def batch_cost_wrapper(w):\n",
    "                linear_loss, squared_loss = compute_batch_cost(\n",
    "                    X_batch, qvae_circuit, w, USE_SWAP_TEST\n",
    "                )\n",
    "                # SWAP 테스트를 사용하는 경우 선형 손실을 최적화 목표로 사용\n",
    "                return linear_loss if USE_SWAP_TEST else squared_loss\n",
    "\n",
    "            # Optimize weights\n",
    "            weights = optimizer.step(batch_cost_wrapper, weights)\n",
    "\n",
    "            # Record loss\n",
    "            linear_loss, squared_loss = compute_batch_cost(\n",
    "                X_batch, qvae_circuit, weights, USE_SWAP_TEST\n",
    "            )\n",
    "            epoch_linear_losses.append(float(linear_loss))\n",
    "            epoch_squared_losses.append(float(squared_loss))\n",
    "\n",
    "        # Epoch summary\n",
    "        avg_linear_loss = np.mean(epoch_linear_losses)\n",
    "        avg_squared_loss = np.mean(epoch_squared_losses)\n",
    "        linear_losses.append(avg_linear_loss)\n",
    "        squared_losses.append(avg_squared_loss)\n",
    "\n",
    "        # SWAP 테스트를 사용하는 경우 선형 손실을 주로 기록\n",
    "        training_losses.append(avg_linear_loss if USE_SWAP_TEST else avg_squared_loss)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            print(\n",
    "                f\"  Epoch {epoch+1:2d}/{epochs} - Linear Loss: {avg_linear_loss:.6f}, Squared Loss: {avg_squared_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Training completed in {training_time:.1f}s - Final loss: {training_losses[-1]:.6f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"strategy\": \"enhanced_qvae\",\n",
    "        \"weights\": weights,\n",
    "        \"losses\": training_losses,\n",
    "        \"linear_losses\": linear_losses,\n",
    "        \"squared_losses\": squared_losses,\n",
    "        \"circuit\": qvae_circuit,\n",
    "        \"n_qubits\": n_qubits,\n",
    "        \"total_qubits\": total_qubits,\n",
    "        \"training_time\": training_time,\n",
    "        \"final_loss\": training_losses[-1],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444383bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING OF BOTH STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "TRAINING: ANGLE EMBEDDING STRATEGY\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Qubits: 4\n",
      "  - Parameters: 48\n",
      "  - Epochs: 100, Batch size: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch  5/100 - Linear Loss: 0.419368, Squared Loss: 0.185423\n",
      "  Epoch 10/100 - Linear Loss: 0.288545, Squared Loss: 0.105884\n",
      "  Epoch 15/100 - Linear Loss: 0.236219, Squared Loss: 0.080546\n",
      "  Epoch 20/100 - Linear Loss: 0.205246, Squared Loss: 0.065483\n",
      "  Epoch 25/100 - Linear Loss: 0.184736, Squared Loss: 0.056785\n",
      "  Epoch 30/100 - Linear Loss: 0.170963, Squared Loss: 0.051965\n",
      "  Epoch 35/100 - Linear Loss: 0.163086, Squared Loss: 0.049310\n",
      "  Epoch 40/100 - Linear Loss: 0.158303, Squared Loss: 0.047613\n",
      "  Epoch 45/100 - Linear Loss: 0.155047, Squared Loss: 0.046428\n",
      "  Epoch 50/100 - Linear Loss: 0.152663, Squared Loss: 0.045579\n",
      "  Epoch 55/100 - Linear Loss: 0.150854, Squared Loss: 0.044968\n",
      "  Epoch 60/100 - Linear Loss: 0.149468, Squared Loss: 0.044523\n",
      "  Epoch 65/100 - Linear Loss: 0.148405, Squared Loss: 0.044192\n",
      "  Epoch 70/100 - Linear Loss: 0.147587, Squared Loss: 0.043938\n",
      "  Epoch 75/100 - Linear Loss: 0.146950, Squared Loss: 0.043738\n",
      "  Epoch 80/100 - Linear Loss: 0.146446, Squared Loss: 0.043576\n",
      "  Epoch 85/100 - Linear Loss: 0.146039, Squared Loss: 0.043442\n",
      "  Epoch 90/100 - Linear Loss: 0.145703, Squared Loss: 0.043329\n",
      "  Epoch 95/100 - Linear Loss: 0.145418, Squared Loss: 0.043232\n",
      "  Epoch 100/100 - Linear Loss: 0.145172, Squared Loss: 0.043148\n",
      "Training completed in 3171.4s - Final loss: 0.043148\n",
      "✓ ANGLE strategy completed successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING: ENHANCED qVAE STRATEGY\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Data Qubits: 8 (4 features × 2 parallel)\n",
      "  - Total Qubits: 13\n",
      "  - Parameters: 64\n",
      "  - Epochs: 100, Batch size: 16\n",
      "  - Features: Re-upload=True, Alternate=True, SWAP=True\n",
      "  Epoch  5/100 - Linear Loss: 0.370625, Squared Loss: 0.137521\n",
      "  Epoch 10/100 - Linear Loss: 0.363031, Squared Loss: 0.132047\n",
      "  Epoch 15/100 - Linear Loss: 0.355876, Squared Loss: 0.127151\n",
      "  Epoch 20/100 - Linear Loss: 0.347259, Squared Loss: 0.121589\n",
      "  Epoch 25/100 - Linear Loss: 0.334575, Squared Loss: 0.113933\n",
      "  Epoch 30/100 - Linear Loss: 0.314874, Squared Loss: 0.103426\n",
      "  Epoch 35/100 - Linear Loss: 0.299417, Squared Loss: 0.096291\n",
      "  Epoch 40/100 - Linear Loss: 0.289885, Squared Loss: 0.092090\n",
      "  Epoch 45/100 - Linear Loss: 0.282969, Squared Loss: 0.089028\n",
      "  Epoch 50/100 - Linear Loss: 0.277854, Squared Loss: 0.086652\n",
      "  Epoch 55/100 - Linear Loss: 0.273304, Squared Loss: 0.084429\n",
      "  Epoch 60/100 - Linear Loss: 0.268649, Squared Loss: 0.082161\n",
      "  Epoch 65/100 - Linear Loss: 0.264278, Squared Loss: 0.080072\n",
      "  Epoch 70/100 - Linear Loss: 0.260444, Squared Loss: 0.078328\n",
      "  Epoch 75/100 - Linear Loss: 0.257094, Squared Loss: 0.076949\n",
      "  Epoch 80/100 - Linear Loss: 0.254065, Squared Loss: 0.075867\n",
      "  Epoch 85/100 - Linear Loss: 0.251314, Squared Loss: 0.075034\n",
      "  Epoch 90/100 - Linear Loss: 0.248865, Squared Loss: 0.074412\n",
      "  Epoch 95/100 - Linear Loss: 0.246697, Squared Loss: 0.073935\n",
      "  Epoch 100/100 - Linear Loss: 0.244790, Squared Loss: 0.073546\n",
      "Training completed in 6452.4s - Final loss: 0.244790\n",
      "✓ ENHANCED qVAE strategy completed successfully\n",
      "\n",
      "================================================================================\n",
      "ALL TRAINING COMPLETED IN 9623.9s\n",
      "================================================================================\n",
      "\n",
      "TRAINING SUMMARY:\n",
      "Strategy        Status     Final Loss   Time (s)   Qubits  \n",
      "-----------------------------------------------------------------\n",
      "angle           SUCCESS    0.043148     3171.4     4       \n",
      "enhanced_qvae   SUCCESS    0.244790     6452.4     13      \n",
      "\n",
      "Ready for evaluation and comparison!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Execute Training for Both Strategies\n",
    "# ==========================================\n",
    "\n",
    "print(\"STARTING TRAINING OF BOTH STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Train Angle strategy\n",
    "try:\n",
    "    angle_result = train_angle_strategy()\n",
    "    results['angle'] = angle_result\n",
    "    print(f\"✓ ANGLE strategy completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ANGLE strategy failed: {str(e)}\")\n",
    "    results['angle'] = {'error': str(e)}\n",
    "\n",
    "# Train Enhanced qVAE strategy\n",
    "try:\n",
    "    qvae_result = train_enhanced_qvae_strategy()\n",
    "    results['enhanced_qvae'] = qvae_result\n",
    "    print(f\"✓ ENHANCED qVAE strategy completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ ENHANCED qVAE strategy failed: {str(e)}\")\n",
    "    results['enhanced_qvae'] = {'error': str(e)}\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ALL TRAINING COMPLETED IN {total_time:.1f}s\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\nTRAINING SUMMARY:\")\n",
    "print(f\"{'Strategy':<15} {'Status':<10} {'Final Loss':<12} {'Time (s)':<10} {'Qubits':<8}\")\n",
    "print(f\"{'-'*65}\")\n",
    "for strategy in ['angle', 'enhanced_qvae']:\n",
    "    if 'error' in results[strategy]:\n",
    "        print(f\"{strategy:<15} {'FAILED':<10} {'N/A':<12} {'N/A':<10} {'N/A':<8}\")\n",
    "    else:\n",
    "        result = results[strategy]\n",
    "        print(f\"{strategy:<15} {'SUCCESS':<10} {result['final_loss']:<12.6f} {result['training_time']:<10.1f} {result['total_qubits']:<8d}\")\n",
    "\n",
    "print(f\"\\nReady for evaluation and comparison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c235bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Evaluation Functions\n",
    "# ==========================================\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute comprehensive evaluation metrics for binary classification.\n",
    "    \n",
    "    Includes standard metrics plus G-Mean which is particularly important\n",
    "    for imbalanced datasets as it balances sensitivity and specificity.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    \n",
    "    # Standard classification metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)  # Sensitivity\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Specificity (True Negative Rate)\n",
    "    spec = tn / (tn + fp) if (tn + fp) else 0.\n",
    "    \n",
    "    # Geometric Mean of Sensitivity and Specificity\n",
    "    # Balanced metric for imbalanced datasets\n",
    "    gmean = (rec * spec) ** 0.5\n",
    "    \n",
    "    return dict(TN=tn, FP=fp, FN=fn, TP=tp,\n",
    "                Accuracy=acc, Precision=prec,\n",
    "                Recall=rec, F1=f1, Specificity=spec, Gmean=gmean)\n",
    "\n",
    "def evaluate_strategy(strategy, result_data, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a single strategy on test data.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATING: {strategy.upper()} STRATEGY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if 'error' in result_data:\n",
    "        print(f\"Strategy failed during training: {result_data['error']}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract trained parameters\n",
    "    weights = result_data['weights']\n",
    "    circuit = result_data['circuit']\n",
    "    \n",
    "    print(f\"Computing reconstruction fidelities for {len(X_test)} test samples...\")\n",
    "    \n",
    "    # Compute fidelities\n",
    "    fidelities = []\n",
    "    for i, x in enumerate(X_test):\n",
    "        if i % 200 == 0:\n",
    "            print(f\"  Processed {i}/{len(X_test)} samples\")\n",
    "        \n",
    "        features = pnp.array(x, requires_grad=False)\n",
    "        \n",
    "        try:\n",
    "            # Use the trained circuit for this strategy\n",
    "            expval = circuit(features, weights)\n",
    "            \n",
    "            # Convert to fidelity\n",
    "            if strategy == \"enhanced_qvae\" and USE_SWAP_TEST:\n",
    "                # SWAP test returns values in range [-1, 1], convert to fidelity [0, 1]\n",
    "                fidelity = (expval + 1) / 2\n",
    "            else:\n",
    "                # Standard expectation value conversion\n",
    "                fidelity = (expval + 1) / 2\n",
    "            \n",
    "            fidelities.append(fidelity)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing sample {i}: {e}\")\n",
    "            fidelities.append(0.5)  # Default fidelity for failed samples\n",
    "    \n",
    "    fidelities = np.array(fidelities)\n",
    "    \n",
    "    print(f\"\\nFidelity statistics:\")\n",
    "    print(f\"  Mean: {np.mean(fidelities):.4f}\")\n",
    "    print(f\"  Std:  {np.std(fidelities):.4f}\")\n",
    "    print(f\"  Min:  {np.min(fidelities):.4f}\")\n",
    "    print(f\"  Max:  {np.max(fidelities):.4f}\")\n",
    "    \n",
    "    # Threshold optimization\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    \n",
    "    best_gmean = 0\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = {}\n",
    "    threshold_results = []\n",
    "    \n",
    "    print(f\"\\nThreshold optimization:\")\n",
    "    for T in thresholds:\n",
    "        # Classification rule: Low fidelity (fidelity < T) indicates fraud\n",
    "        y_pred = (fidelities < T).astype(int)\n",
    "        m = compute_metrics(y_test, y_pred)\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': T,\n",
    "            'metrics': m\n",
    "        })\n",
    "        \n",
    "        print(f\"  T={T:.1f}: Acc={m['Accuracy']:.3f} Prec={m['Precision']:.3f} Rec={m['Recall']:.3f} F1={m['F1']:.3f} G-Mean={m['Gmean']:.3f}\")\n",
    "        \n",
    "        # Track best performance by G-Mean\n",
    "        if m['Gmean'] > best_gmean:\n",
    "            best_gmean = m['Gmean']\n",
    "            best_threshold = T\n",
    "            best_metrics = m\n",
    "    \n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, 1 - fidelities)  # 1-fidelity for anomaly score\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    # Ensure best_metrics has all required keys with default values\n",
    "    if not best_metrics:\n",
    "        best_metrics = {\n",
    "            'TN': 0, 'FP': 0, 'FN': 0, 'TP': 0,\n",
    "            'Accuracy': 0.0, 'Precision': 0.0,\n",
    "            'Recall': 0.0, 'F1': 0.0, 'Specificity': 0.0, 'Gmean': 0.0\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nRESULTS SUMMARY:\")\n",
    "    print(f\"  AUC-ROC Score: {auc:.4f}\")\n",
    "    print(f\"  Best Threshold: {best_threshold} (G-Mean: {best_gmean:.3f})\")\n",
    "    print(f\"  Best Performance: Acc={best_metrics.get('Accuracy', 0):.3f}, \"\n",
    "          f\"Prec={best_metrics.get('Precision', 0):.3f}, \"\n",
    "          f\"Rec={best_metrics.get('Recall', 0):.3f}, \"\n",
    "          f\"F1={best_metrics.get('F1', 0):.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'strategy': strategy,\n",
    "        'fidelities': fidelities,\n",
    "        'auc_roc': auc,\n",
    "        'best_threshold': best_threshold,\n",
    "        'best_gmean': best_gmean,\n",
    "        'best_metrics': best_metrics,\n",
    "        'threshold_results': threshold_results,\n",
    "        'training_time': result_data['training_time'],\n",
    "        'final_loss': result_data['final_loss'],\n",
    "        'n_qubits': result_data['n_qubits'],\n",
    "        'total_qubits': result_data['total_qubits']\n",
    "    }\n",
    "\n",
    "print(\"Evaluation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b378ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EVALUATION OF BOTH STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: ANGLE STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 0.8480\n",
      "  Std:  0.1632\n",
      "  Min:  0.2310\n",
      "  Max:  0.9973\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.505 Prec=0.667 Rec=0.021 F1=0.041 G-Mean=0.144\n",
      "  T=0.4: Acc=0.516 Prec=0.800 Rec=0.042 F1=0.080 G-Mean=0.204\n",
      "  T=0.5: Acc=0.547 Prec=0.846 Rec=0.116 F1=0.204 G-Mean=0.337\n",
      "  T=0.6: Acc=0.568 Prec=0.842 Rec=0.168 F1=0.281 G-Mean=0.404\n",
      "  T=0.7: Acc=0.589 Prec=0.793 Rec=0.242 F1=0.371 G-Mean=0.476\n",
      "  T=0.8: Acc=0.632 Prec=0.805 Rec=0.347 F1=0.485 G-Mean=0.564\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.8048\n",
      "  Best Threshold: 0.8 (G-Mean: 0.564)\n",
      "  Best Performance: Acc=0.632, Prec=0.805, Rec=0.347, F1=0.485\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: ENHANCED_QVAE STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 0.7561\n",
      "  Std:  0.1190\n",
      "  Min:  0.5301\n",
      "  Max:  0.9692\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.4: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.5: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.6: Acc=0.558 Prec=0.824 Rec=0.147 F1=0.250 G-Mean=0.378\n",
      "  T=0.7: Acc=0.763 Prec=0.838 Rec=0.653 F1=0.734 G-Mean=0.755\n",
      "  T=0.8: Acc=0.768 Prec=0.718 Rec=0.884 F1=0.792 G-Mean=0.760\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.8660\n",
      "  Best Threshold: 0.8 (G-Mean: 0.760)\n",
      "  Best Performance: Acc=0.768, Prec=0.718, Rec=0.884, F1=0.792\n",
      "\n",
      "================================================================================\n",
      "ALL EVALUATIONS COMPLETED IN 11.4s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Execute Evaluation for Both Strategies\n",
    "# ==========================================\n",
    "\n",
    "print(\"STARTING EVALUATION OF BOTH STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "evaluation_results = {}\n",
    "eval_start_time = time.time()\n",
    "\n",
    "# Evaluate each strategy\n",
    "for strategy in ['angle', 'enhanced_qvae']:\n",
    "    if strategy in results:\n",
    "        eval_result = evaluate_strategy(strategy, results[strategy], X_test_4d, y_test)\n",
    "        if eval_result is not None:\n",
    "            evaluation_results[strategy] = eval_result\n",
    "\n",
    "total_eval_time = time.time() - eval_start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ALL EVALUATIONS COMPLETED IN {total_eval_time:.1f}s\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b232abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPARISON: ANGLE vs ENHANCED qVAE\n",
      "====================================================================================================\n",
      "\n",
      "PERFORMANCE COMPARISON:\n",
      "Metric               Angle        Enhanced qVAE   Improvement \n",
      "-----------------------------------------------------------------\n",
      "AUC-ROC              0.8048       0.8660          +7.6%\n",
      "G-Mean               0.564        0.760           +34.7%\n",
      "F1-Score             0.485        0.792           +63.3%\n",
      "Training Time (s)    3171.4       6452.4          2.0x slower\n",
      "Qubits Used          4            13              3.2x more\n",
      "AUC per Qubit        0.2012       0.0666          -66.9%\n",
      "\n",
      "====================================================================================================\n",
      "CONCLUSION ANALYSIS\n",
      "====================================================================================================\n",
      "WINNER: Enhanced qVAE with AUC-ROC = 0.8660\n",
      "Performance Improvement: +7.6% better AUC-ROC\n",
      "Advanced Features: Data re-uploading, parallel embedding, SWAP test\n",
      "Resource Cost: 3.2x more qubits, 2.0x longer training\n",
      "Resource Efficiency: -66.9% less efficient per qubit\n",
      "\n",
      "KEY INSIGHTS:\n",
      "• AUC-ROC Improvement: +7.6% (Enhanced qVAE vs Angle)\n",
      "• Computational Cost: 2.0x training time, 3.2x qubits\n",
      "• Advanced qVAE features justify the additional complexity\n",
      "• SWAP test measurement provides quantum fidelity estimates\n",
      "• Data re-uploading increases expressivity at each layer\n",
      "• 2x parallel embedding replicates features across qubits\n",
      "\n",
      "RECOMMENDATION:\n",
      "Consider Enhanced qVAE: Moderate improvement (+7.6%) with higher cost\n",
      "\n",
      "====================================================================================================\n",
      "FRAUD DETECTION CAPABILITY: ENHANCED QVAE achieves 0.8660 AUC-ROC\n",
      "====================================================================================================\n",
      "\n",
      "Comparison completed. Results stored in 'final_comparison' variable.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Final Comparison and Analysis\n",
    "# ==========================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"FINAL COMPARISON: ANGLE vs ENHANCED qVAE\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "if len(evaluation_results) == 0:\n",
    "    print(\"No strategies were successfully evaluated!\")\n",
    "elif len(evaluation_results) == 1:\n",
    "    strategy = list(evaluation_results.keys())[0]\n",
    "    print(f\"Only {strategy.upper()} was successfully evaluated.\")\n",
    "    result = evaluation_results[strategy]\n",
    "    print(f\"  AUC-ROC: {result['auc_roc']:.4f}\")\n",
    "    print(f\"  Best G-Mean: {result['best_gmean']:.3f}\")\n",
    "    print(f\"  Training Time: {result['training_time']:.1f}s\")\n",
    "else:\n",
    "    # Both strategies evaluated successfully\n",
    "    angle_result = evaluation_results['angle']\n",
    "    qvae_result = evaluation_results['enhanced_qvae']\n",
    "    \n",
    "    print(f\"\\nPERFORMANCE COMPARISON:\")\n",
    "    print(f\"{'Metric':<20} {'Angle':<12} {'Enhanced qVAE':<15} {'Improvement':<12}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    \n",
    "    # AUC-ROC comparison\n",
    "    angle_auc = angle_result['auc_roc']\n",
    "    qvae_auc = qvae_result['auc_roc']\n",
    "    auc_improvement = ((qvae_auc - angle_auc) / angle_auc) * 100\n",
    "    print(f\"{'AUC-ROC':<20} {angle_auc:<12.4f} {qvae_auc:<15.4f} {auc_improvement:+.1f}%\")\n",
    "    \n",
    "    # G-Mean comparison\n",
    "    angle_gmean = angle_result['best_gmean']\n",
    "    qvae_gmean = qvae_result['best_gmean']\n",
    "    gmean_improvement = ((qvae_gmean - angle_gmean) / angle_gmean) * 100\n",
    "    print(f\"{'G-Mean':<20} {angle_gmean:<12.3f} {qvae_gmean:<15.3f} {gmean_improvement:+.1f}%\")\n",
    "    \n",
    "    # F1-Score comparison\n",
    "    angle_f1 = angle_result['best_metrics'].get('F1', 0)\n",
    "    qvae_f1 = qvae_result['best_metrics'].get('F1', 0)\n",
    "    f1_improvement = ((qvae_f1 - angle_f1) / angle_f1) * 100 if angle_f1 > 0 else 0\n",
    "    print(f\"{'F1-Score':<20} {angle_f1:<12.3f} {qvae_f1:<15.3f} {f1_improvement:+.1f}%\")\n",
    "    \n",
    "    # Training time comparison\n",
    "    angle_time = angle_result['training_time']\n",
    "    qvae_time = qvae_result['training_time']\n",
    "    time_ratio = qvae_time / angle_time\n",
    "    print(f\"{'Training Time (s)':<20} {angle_time:<12.1f} {qvae_time:<15.1f} {time_ratio:.1f}x slower\")\n",
    "    \n",
    "    # Qubit usage comparison\n",
    "    angle_qubits = angle_result['total_qubits']\n",
    "    qvae_qubits = qvae_result['total_qubits']\n",
    "    qubit_ratio = qvae_qubits / angle_qubits\n",
    "    print(f\"{'Qubits Used':<20} {angle_qubits:<12d} {qvae_qubits:<15d} {qubit_ratio:.1f}x more\")\n",
    "    \n",
    "    # Resource efficiency\n",
    "    angle_efficiency = angle_auc / angle_qubits\n",
    "    qvae_efficiency = qvae_auc / qvae_qubits\n",
    "    efficiency_improvement = ((qvae_efficiency - angle_efficiency) / angle_efficiency) * 100\n",
    "    print(f\"{'AUC per Qubit':<20} {angle_efficiency:<12.4f} {qvae_efficiency:<15.4f} {efficiency_improvement:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"CONCLUSION ANALYSIS\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Determine winner\n",
    "    if qvae_auc > angle_auc:\n",
    "        winner = \"Enhanced qVAE\"\n",
    "        winner_auc = qvae_auc\n",
    "        print(f\"WINNER: {winner} with AUC-ROC = {winner_auc:.4f}\")\n",
    "        print(f\"Performance Improvement: {auc_improvement:+.1f}% better AUC-ROC\")\n",
    "        print(f\"Advanced Features: Data re-uploading, parallel embedding, SWAP test\")\n",
    "        print(f\"Resource Cost: {qubit_ratio:.1f}x more qubits, {time_ratio:.1f}x longer training\")\n",
    "        \n",
    "        if efficiency_improvement > 0:\n",
    "            print(f\"Resource Efficiency: {efficiency_improvement:+.1f}% better performance per qubit\")\n",
    "        else:\n",
    "            print(f\"Resource Efficiency: {efficiency_improvement:.1f}% less efficient per qubit\")\n",
    "    else:\n",
    "        winner = \"Angle Embedding\"\n",
    "        winner_auc = angle_auc\n",
    "        print(f\"WINNER: {winner} with AUC-ROC = {winner_auc:.4f}\")\n",
    "        print(f\"Simplicity: Standard approach with good performance\")\n",
    "        print(f\"Resource Efficiency: {angle_qubits} qubits, {angle_time:.1f}s training\")\n",
    "        print(f\"Enhanced qVAE underperformed despite advanced features\")\n",
    "    \n",
    "    print(f\"\\nKEY INSIGHTS:\")\n",
    "    print(f\"• AUC-ROC Improvement: {auc_improvement:+.1f}% (Enhanced qVAE vs Angle)\")\n",
    "    print(f\"• Computational Cost: {time_ratio:.1f}x training time, {qubit_ratio:.1f}x qubits\")\n",
    "    print(f\"• Advanced qVAE features {'justify' if auc_improvement > 5 else 'may not justify'} the additional complexity\")\n",
    "    \n",
    "    if USE_SWAP_TEST:\n",
    "        print(f\"• SWAP test measurement provides quantum fidelity estimates\")\n",
    "    if USE_DATA_REUPLOADING:\n",
    "        print(f\"• Data re-uploading increases expressivity at each layer\")\n",
    "    if USE_PARALLEL_EMBEDDING > 1:\n",
    "        print(f\"• {USE_PARALLEL_EMBEDDING}x parallel embedding replicates features across qubits\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDATION:\")\n",
    "    if auc_improvement > 10:\n",
    "        print(f\"Use Enhanced qVAE: Significant performance improvement ({auc_improvement:+.1f}%)\")\n",
    "    elif auc_improvement > 5:\n",
    "        print(f\"Consider Enhanced qVAE: Moderate improvement ({auc_improvement:+.1f}%) with higher cost\")\n",
    "    else:\n",
    "        print(f\"Use Angle Embedding: Better resource efficiency for similar performance\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"FRAUD DETECTION CAPABILITY: {winner.upper()} achieves {winner_auc:.4f} AUC-ROC\")\n",
    "    print(f\"{'='*100}\")\n",
    "\n",
    "# Store final results\n",
    "final_comparison = evaluation_results\n",
    "print(f\"\\nComparison completed. Results stored in 'final_comparison' variable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
